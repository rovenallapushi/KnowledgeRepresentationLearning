{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "84c9c28b-b693-4af4-a85f-94a08cd1f7bb",
      "metadata": {
        "id": "84c9c28b-b693-4af4-a85f-94a08cd1f7bb"
      },
      "source": [
        "## First dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d05e4b2-4da1-4880-81b5-8cd4641dfa25",
      "metadata": {
        "id": "4d05e4b2-4da1-4880-81b5-8cd4641dfa25"
      },
      "source": [
        "### Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-sat"
      ],
      "metadata": {
        "id": "ydT6rlxeIRQF"
      },
      "id": "ydT6rlxeIRQF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bnlearn"
      ],
      "metadata": {
        "id": "NL0PNfbHVZNb"
      },
      "id": "NL0PNfbHVZNb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pysmt"
      ],
      "metadata": {
        "id": "_6elN2hiyy_0"
      },
      "id": "_6elN2hiyy_0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4765cc0",
      "metadata": {
        "id": "c4765cc0"
      },
      "outputs": [],
      "source": [
        "from pysat.solvers import Minisat22\n",
        "from pysat.formula import CNF\n",
        "import bnlearn as bn\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pysmt.shortcuts import Symbol, And, Not, Iff, Or, get_env\n",
        "from pysmt.typing import BOOL\n",
        "from pysmt.smtlib.parser import SmtLibParser\n",
        "from pysat.formula import CNF\n",
        "from pysat.solvers import Solver\n",
        "from sympy import symbols\n",
        "from sympy import symbols, Rational"
      ],
      "metadata": {
        "id": "H_Xhntnjyu2y"
      },
      "id": "H_Xhntnjyu2y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing dataset"
      ],
      "metadata": {
        "id": "NP5mWXTAsDLr"
      },
      "id": "NP5mWXTAsDLr"
    },
    {
      "cell_type": "markdown",
      "id": "dcf46de0-6a01-490d-b149-6449dec0b4de",
      "metadata": {
        "id": "dcf46de0-6a01-490d-b149-6449dec0b4de"
      },
      "source": [
        "\n",
        "* Asia: BN of eight binary variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "314e3ec4",
      "metadata": {
        "id": "314e3ec4",
        "outputId": "aaedde9a-7a76-49a8-83a2-8b18f5686355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[bnlearn] >Import <asia>\n",
            "[bnlearn] >Loading bif file </usr/local/lib/python3.10/dist-packages/datazets/data/asia.bif>\n",
            "[bnlearn] >Check whether CPDs sum up to one.\n"
          ]
        }
      ],
      "source": [
        "datasets = [\"asia\"]\n",
        "dataset = datasets[0]\n",
        "df = bn.import_DAG(dataset, CPD = True)\n",
        "CPDs = bn.print_CPD(df, verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is how the CPDs table looks like:"
      ],
      "metadata": {
        "id": "nC5Sq1ycybsl"
      },
      "id": "nC5Sq1ycybsl"
    },
    {
      "cell_type": "code",
      "source": [
        "CPDs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDNWPvzvuxYS",
        "outputId": "bd8ce815-ae3e-4fdf-c6d8-21a3b834b5b2"
      },
      "id": "DDNWPvzvuxYS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'asia':    asia     p\n",
              " 0     0  0.01\n",
              " 1     1  0.99,\n",
              " 'bronc':    bronc  smoke    p\n",
              " 0      0      0  0.6\n",
              " 1      0      1  0.3\n",
              " 2      1      0  0.4\n",
              " 3      1      1  0.7,\n",
              " 'dysp':    dysp  bronc  either    p\n",
              " 0     0      0       0  0.9\n",
              " 1     0      0       1  0.8\n",
              " 2     0      1       0  0.7\n",
              " 3     0      1       1  0.1\n",
              " 4     1      0       0  0.1\n",
              " 5     1      0       1  0.2\n",
              " 6     1      1       0  0.3\n",
              " 7     1      1       1  0.9,\n",
              " 'either':    either  lung  tub    p\n",
              " 0       0     0    0  1.0\n",
              " 1       0     0    1  1.0\n",
              " 2       0     1    0  1.0\n",
              " 3       0     1    1  0.0\n",
              " 4       1     0    0  0.0\n",
              " 5       1     0    1  0.0\n",
              " 6       1     1    0  0.0\n",
              " 7       1     1    1  1.0,\n",
              " 'lung':    lung  smoke     p\n",
              " 0     0      0  0.10\n",
              " 1     0      1  0.01\n",
              " 2     1      0  0.90\n",
              " 3     1      1  0.99,\n",
              " 'smoke':    smoke    p\n",
              " 0      0  0.5\n",
              " 1      1  0.5,\n",
              " 'tub':    tub  asia     p\n",
              " 0    0     0  0.05\n",
              " 1    0     1  0.01\n",
              " 2    1     0  0.95\n",
              " 3    1     1  0.99,\n",
              " 'xray':    xray  either     p\n",
              " 0     0       0  0.98\n",
              " 1     0       1  0.05\n",
              " 2     1       0  0.02\n",
              " 3     1       1  0.95}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities"
      ],
      "metadata": {
        "id": "iO68wlm86fCk"
      },
      "id": "iO68wlm86fCk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Find the parent of every variable. This will help in introducing the right number of the variables for the child node, according to the combinations of the parent Truth assignments"
      ],
      "metadata": {
        "id": "VbA5Zb_904rL"
      },
      "id": "VbA5Zb_904rL"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parents_dict(dataframes_dict):\n",
        "    parent_dict = {}\n",
        "\n",
        "    for key, df in dataframes_dict.items():\n",
        "        # Identify parent columns by excluding the target column and the probability column 'p'\n",
        "        parent_columns = [col for col in df.columns if col not in {key, 'p'}]\n",
        "        parent_dict[key] = parent_columns\n",
        "\n",
        "    return parent_dict"
      ],
      "metadata": {
        "id": "70vz9a_mLYlW"
      },
      "id": "70vz9a_mLYlW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parent_dict = get_parents_dict(CPDs)"
      ],
      "metadata": {
        "id": "6JJWjtHkOG1-"
      },
      "id": "6JJWjtHkOG1-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parent_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz8CLKIPPHQv",
        "outputId": "1f5b6578-bb9a-4847-e219-cded60fb904a"
      },
      "id": "pz8CLKIPPHQv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'asia': [],\n",
              " 'bronc': ['smoke'],\n",
              " 'dysp': ['bronc', 'either'],\n",
              " 'either': ['lung', 'tub'],\n",
              " 'lung': ['smoke'],\n",
              " 'smoke': [],\n",
              " 'tub': ['asia'],\n",
              " 'xray': ['either']}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding BN in WMC"
      ],
      "metadata": {
        "id": "Ob5DSdGu4_-h"
      },
      "id": "Ob5DSdGu4_-h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Create new propositional variables"
      ],
      "metadata": {
        "id": "Xr2bdRNksK0w"
      },
      "id": "Xr2bdRNksK0w"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_propositional_variables(cpt, parent_dict):\n",
        "\n",
        "    \"\"\"\n",
        "    Create propositional variables for a given Conditional Probability Table (CPT) and its parent relationships.\n",
        "\n",
        "    Parameters:\n",
        "    - cpt (dict): A dictionary representing the Conditional Probability Table (CPT). The keys are variable names.\n",
        "    - parent_dict (dict): A dictionary where keys are variable names and values are lists of parent variables.\n",
        "\n",
        "    Returns:\n",
        "    - all_vars (list): A list of all variable names extracted from the CPT.\n",
        "    - var_symbols (dict): A dictionary mapping each variable name to its corresponding symbolic representation.\n",
        "    - indicator_vars (dict): A dictionary containing indicator variables. For root nodes, the indicator variable is the\n",
        "      same as the variable symbol. For non-root nodes, indicator variables are created for each possible configuration\n",
        "      of parent variables.\n",
        "\n",
        "    Example:\n",
        "    >>> cpt = {'A': [0.2, 0.8], 'B': [0.5, 0.5]}\n",
        "    >>> parent_dict = {'B': ['A']}\n",
        "    >>> all_vars, var_symbols, indicator_vars = create_propositional_variables(cpt, parent_dict)\n",
        "    >>> all_vars\n",
        "    ['A', 'B']\n",
        "    >>> var_symbols\n",
        "    {'A': A, 'B': B}\n",
        "    >>> indicator_vars\n",
        "    {'A': A, 'B': B, 'B00': B00, 'B01': B01, 'B10': B10, 'B11': B11}\n",
        "    \"\"\"\n",
        "\n",
        "    all_vars = list(cpt.keys())\n",
        "\n",
        "    # Create symbols for all variables\n",
        "    var_symbols = {var: symbols(var) for var in all_vars}\n",
        "\n",
        "    # Create indicator variables\n",
        "    indicator_vars = {}\n",
        "    for var in all_vars:\n",
        "        parents = parent_dict.get(var, [])\n",
        "        if not parents:  # For root nodes\n",
        "            indicator_vars[var] = symbols(var)\n",
        "        else:\n",
        "\n",
        "          indicator_vars[var] = symbols(var)\n",
        "\n",
        "          from itertools import product\n",
        "          num_parents = len(parents)\n",
        "          for config in product([0, 1], repeat=num_parents):\n",
        "            indicator_name = f\"{var}{''.join(map(str, config))}\"\n",
        "            indicator_vars[indicator_name] = symbols(indicator_name)\n",
        "\n",
        "    return all_vars, var_symbols, indicator_vars"
      ],
      "metadata": {
        "id": "wjB2yywPSzwT"
      },
      "id": "wjB2yywPSzwT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_vars, var_symbols, indicator_vars = create_propositional_variables(CPDs, parent_dict)"
      ],
      "metadata": {
        "id": "6k1nk4seS66f"
      },
      "id": "6k1nk4seS66f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the result: Despite the variables presented in the CPTs table, I have introduced new variables for each chiled node based on the number of parents. For example, the state variable ''dysp has two parents, thereforeI have introduced 4 new variables, each of them represents the combinations of different truth assignments of parents ['bronc', 'either']"
      ],
      "metadata": {
        "id": "W_3SXPgy4EX8"
      },
      "id": "W_3SXPgy4EX8"
    },
    {
      "cell_type": "code",
      "source": [
        "indicator_vars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fTqje6qpQ6D",
        "outputId": "ae8fe4d6-8130-48a9-95df-678bc69051b4"
      },
      "id": "-fTqje6qpQ6D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'asia': asia,\n",
              " 'bronc': bronc,\n",
              " 'bronc0': bronc0,\n",
              " 'bronc1': bronc1,\n",
              " 'dysp': dysp,\n",
              " 'dysp00': dysp00,\n",
              " 'dysp01': dysp01,\n",
              " 'dysp10': dysp10,\n",
              " 'dysp11': dysp11,\n",
              " 'either': either,\n",
              " 'either00': either00,\n",
              " 'either01': either01,\n",
              " 'either10': either10,\n",
              " 'either11': either11,\n",
              " 'lung': lung,\n",
              " 'lung0': lung0,\n",
              " 'lung1': lung1,\n",
              " 'smoke': smoke,\n",
              " 'tub': tub,\n",
              " 'tub0': tub0,\n",
              " 'tub1': tub1,\n",
              " 'xray': xray,\n",
              " 'xray0': xray0,\n",
              " 'xray1': xray1}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2, 3, 4: The function below assing the weights to the literals based on the following rules:\n",
        "\n",
        "*   Assing the weight to the literal that has no parent as the\n",
        "*   For the new introduced positive literal, given the truth values of the parents, check the entry in the table and assign it\n",
        "*  For the negative ones, substruct the positive weight from one\n",
        "*   For the other literals, that has no entry in th table, assign 1 as weight value\n"
      ],
      "metadata": {
        "id": "XOSyT1xY41Oa"
      },
      "id": "XOSyT1xY41Oa"
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_weights(cpt, parent_dict, indicator_vars):\n",
        "\n",
        "    \"\"\"\n",
        "    Assigns weights to indicator variables based on conditional probability tables (CPTs) and parent-child relationships.\n",
        "\n",
        "    Parameters:\n",
        "    - cpt (dict): A dictionary where the keys are variable names and the values are pandas DataFrames. Each DataFrame\n",
        "      contains the CPT for the variable, with the last column being the probability 'p' and the other columns representing\n",
        "      the variable and its parent values.\n",
        "    - parent_dict (dict): A dictionary where the keys are variable names and the values are lists of parent variable names.\n",
        "    - indicator_vars (dict): A dictionary mapping variable names and their configurations (as strings) to indicator variable\n",
        "      symbols.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary where the keys are indicator variable symbols and their negations (as sympy symbols) and the values\n",
        "      are the assigned weights (float). The weights represent the probabilities for the positive literals and their complements\n",
        "      for the negative literals.\n",
        "    \"\"\"\n",
        "    weights = {}\n",
        "\n",
        "    for var, df in cpt.items():\n",
        "        parents = parent_dict.get(var, [])\n",
        "\n",
        "        if not parents:  # Root node\n",
        "            weight = df.loc[df[var] == 1, 'p'].values[0]\n",
        "            weights[indicator_vars[var]] = round(float(weight),6)\n",
        "        else:\n",
        "            for _, row in df.iterrows():\n",
        "                config = tuple(row[parents])\n",
        "                prob = row['p']\n",
        "                indicator_name = f\"{var}{''.join(map(str, map(int, config)))}\"\n",
        "                weights[indicator_vars[indicator_name]] = round(float(prob),6)\n",
        "\n",
        "    # Set negative weights\n",
        "    neg_weights = {symbols(f\"¬{var}\"): round((1 - weight),6) for var, weight in weights.items()}\n",
        "\n",
        "    # Combine positive and negative weights\n",
        "    all_weights = {**weights, **neg_weights}\n",
        "\n",
        "    # Set weights for all other literals to 1\n",
        "    all_vars = set(indicator_vars.values())\n",
        "    for var in all_vars:\n",
        "        if var not in all_weights:\n",
        "          neg_var = symbols(f\"¬{var}\")\n",
        "          all_weights[var] = 1.0\n",
        "          all_weights[neg_var] = 1.0\n",
        "\n",
        "    return all_weights"
      ],
      "metadata": {
        "id": "mMYIGxW7Umby"
      },
      "id": "mMYIGxW7Umby",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights = assign_weights(CPDs, parent_dict, indicator_vars)"
      ],
      "metadata": {
        "id": "6OETxn16bY4n"
      },
      "id": "6OETxn16bY4n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvLPlt8_bf24",
        "outputId": "b268a13a-8d3b-4c22-973a-4f74cc29eb89"
      },
      "id": "vvLPlt8_bf24",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{asia: 0.99,\n",
              " bronc0: 0.4,\n",
              " bronc1: 0.7,\n",
              " dysp00: 0.1,\n",
              " dysp01: 0.2,\n",
              " dysp10: 0.3,\n",
              " dysp11: 0.9,\n",
              " either00: 0.0,\n",
              " either01: 0.0,\n",
              " either10: 0.0,\n",
              " either11: 1.0,\n",
              " lung0: 0.9,\n",
              " lung1: 0.99,\n",
              " smoke: 0.5,\n",
              " tub0: 0.95,\n",
              " tub1: 0.99,\n",
              " xray0: 0.02,\n",
              " xray1: 0.95,\n",
              " ¬asia: 0.01,\n",
              " ¬bronc0: 0.6,\n",
              " ¬bronc1: 0.3,\n",
              " ¬dysp00: 0.9,\n",
              " ¬dysp01: 0.8,\n",
              " ¬dysp10: 0.7,\n",
              " ¬dysp11: 0.1,\n",
              " ¬either00: 1.0,\n",
              " ¬either01: 1.0,\n",
              " ¬either10: 1.0,\n",
              " ¬either11: 0.0,\n",
              " ¬lung0: 0.1,\n",
              " ¬lung1: 0.01,\n",
              " ¬smoke: 0.5,\n",
              " ¬tub0: 0.05,\n",
              " ¬tub1: 0.01,\n",
              " ¬xray0: 0.98,\n",
              " ¬xray1: 0.05,\n",
              " tub: 1.0,\n",
              " ¬tub: 1.0,\n",
              " bronc: 1.0,\n",
              " ¬bronc: 1.0,\n",
              " either: 1.0,\n",
              " ¬either: 1.0,\n",
              " xray: 1.0,\n",
              " ¬xray: 1.0,\n",
              " lung: 1.0,\n",
              " ¬lung: 1.0,\n",
              " dysp: 1.0,\n",
              " ¬dysp: 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5. This function create the implications to be used from Sat Solver."
      ],
      "metadata": {
        "id": "-m0-S3fFBu4b"
      },
      "id": "-m0-S3fFBu4b"
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def generate_equivalences(dataframes_dict):\n",
        "    \"\"\"\n",
        "    Generates logical equivalences based on conditional probability tables (CPTs) provided in a dictionary of DataFrames.\n",
        "\n",
        "    Parameters:\n",
        "    - dataframes_dict (dict): A dictionary where the keys are target variable names and the values are pandas DataFrames.\n",
        "      Each DataFrame contains the CPT for the target variable, with columns representing the parent variables, the target\n",
        "      variable, and a probability column 'p'.\n",
        "\n",
        "    Returns:\n",
        "    - list: A list of strings, where each string is a logical equivalence derived from the CPTs.\n",
        "    \"\"\"\n",
        "    equivalences = []\n",
        "\n",
        "    for key, df in dataframes_dict.items():\n",
        "        # Identify parent columns by excluding the target column and the probability column 'p'\n",
        "        parent_columns = [col for col in df.columns if col not in {key, 'p'}]\n",
        "\n",
        "        if not parent_columns:\n",
        "            continue\n",
        "\n",
        "        # Generate all binary combinations of parent columns\n",
        "        k = len(parent_columns)\n",
        "        for b in itertools.product([0, 1], repeat=k):\n",
        "            pb = f\"{key}{''.join(map(str, b))}\"\n",
        "            parents_true = [f\"{parent}\" for parent, bit in zip(parent_columns, b) if bit == 1]\n",
        "            parents_false = [f\"¬{parent}\" for parent, bit in zip(parent_columns, b) if bit == 0]\n",
        "            parent_clauses = \" ∧ \".join(parents_true + parents_false)\n",
        "            equivalence = f\"{key} ∧ {parent_clauses} → {pb}\"\n",
        "\n",
        "            equivalences.append(equivalence)\n",
        "\n",
        "\n",
        "            neg_pb = f\"¬{pb}\"\n",
        "            neg_key = f\"¬{key}\"\n",
        "            neg_parent_clauses = \" ∧ \".join(parents_true + parents_false)\n",
        "            neg_equivalence = f\"{neg_key} ∧ {neg_parent_clauses} → {neg_pb}\"\n",
        "\n",
        "\n",
        "            equivalences.append(neg_equivalence)\n",
        "\n",
        "    return equivalences\n"
      ],
      "metadata": {
        "id": "cFgzDSz6kXEs"
      },
      "id": "cFgzDSz6kXEs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equivalences = generate_equivalences(CPDs)"
      ],
      "metadata": {
        "id": "ZuP8737nMtHY"
      },
      "id": "ZuP8737nMtHY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equivalences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_GRgOK2ZROb",
        "outputId": "c4ae2ba0-c5f3-4730-d171-44c1bacfa0b6"
      },
      "id": "S_GRgOK2ZROb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bronc ∧ ¬smoke → bronc0',\n",
              " '¬bronc ∧ ¬smoke → ¬bronc0',\n",
              " 'bronc ∧ smoke → bronc1',\n",
              " '¬bronc ∧ smoke → ¬bronc1',\n",
              " 'dysp ∧ ¬bronc ∧ ¬either → dysp00',\n",
              " '¬dysp ∧ ¬bronc ∧ ¬either → ¬dysp00',\n",
              " 'dysp ∧ either ∧ ¬bronc → dysp01',\n",
              " '¬dysp ∧ either ∧ ¬bronc → ¬dysp01',\n",
              " 'dysp ∧ bronc ∧ ¬either → dysp10',\n",
              " '¬dysp ∧ bronc ∧ ¬either → ¬dysp10',\n",
              " 'dysp ∧ bronc ∧ either → dysp11',\n",
              " '¬dysp ∧ bronc ∧ either → ¬dysp11',\n",
              " 'either ∧ ¬lung ∧ ¬tub → either00',\n",
              " '¬either ∧ ¬lung ∧ ¬tub → ¬either00',\n",
              " 'either ∧ tub ∧ ¬lung → either01',\n",
              " '¬either ∧ tub ∧ ¬lung → ¬either01',\n",
              " 'either ∧ lung ∧ ¬tub → either10',\n",
              " '¬either ∧ lung ∧ ¬tub → ¬either10',\n",
              " 'either ∧ lung ∧ tub → either11',\n",
              " '¬either ∧ lung ∧ tub → ¬either11',\n",
              " 'lung ∧ ¬smoke → lung0',\n",
              " '¬lung ∧ ¬smoke → ¬lung0',\n",
              " 'lung ∧ smoke → lung1',\n",
              " '¬lung ∧ smoke → ¬lung1',\n",
              " 'tub ∧ ¬asia → tub0',\n",
              " '¬tub ∧ ¬asia → ¬tub0',\n",
              " 'tub ∧ asia → tub1',\n",
              " '¬tub ∧ asia → ¬tub1',\n",
              " 'xray ∧ ¬either → xray0',\n",
              " '¬xray ∧ ¬either → ¬xray0',\n",
              " 'xray ∧ either → xray1',\n",
              " '¬xray ∧ either → ¬xray1']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities to transform the problem for the SAT solver"
      ],
      "metadata": {
        "id": "JrKq2WmyblV-"
      },
      "id": "JrKq2WmyblV-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Make sure that every positive literal is given a distinct positive integer and that every negative literal is given the same integer with a negative sign by mapping each literal to an integer value."
      ],
      "metadata": {
        "id": "FS0MGoZiDEPb"
      },
      "id": "FS0MGoZiDEPb"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_symbol_mapping(equivalences):\n",
        "    symbol_mapping = {}\n",
        "    counter = 1\n",
        "\n",
        "    for implication in equivalences:\n",
        "        literals = implication.replace('→', '∧').replace('¬', '').split('∧')\n",
        "        for literal in literals:\n",
        "            literal = literal.strip()\n",
        "            if literal not in symbol_mapping:\n",
        "                symbol_mapping[literal] = counter\n",
        "                symbol_mapping[f'¬{literal}'] = -counter\n",
        "                counter += 1\n",
        "\n",
        "    return symbol_mapping"
      ],
      "metadata": {
        "id": "TjCslcpcdgnr"
      },
      "id": "TjCslcpcdgnr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbol_mapping = create_symbol_mapping(equivalences)"
      ],
      "metadata": {
        "id": "D8NHt-qLEUdn"
      },
      "id": "D8NHt-qLEUdn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbol_mapping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTzoCENYEb1r",
        "outputId": "8d3f7fa4-41db-4ad9-8087-81d677d0f029"
      },
      "id": "nTzoCENYEb1r",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bronc': 1,\n",
              " '¬bronc': -1,\n",
              " 'smoke': 2,\n",
              " '¬smoke': -2,\n",
              " 'bronc0': 3,\n",
              " '¬bronc0': -3,\n",
              " 'bronc1': 4,\n",
              " '¬bronc1': -4,\n",
              " 'dysp': 5,\n",
              " '¬dysp': -5,\n",
              " 'either': 6,\n",
              " '¬either': -6,\n",
              " 'dysp00': 7,\n",
              " '¬dysp00': -7,\n",
              " 'dysp01': 8,\n",
              " '¬dysp01': -8,\n",
              " 'dysp10': 9,\n",
              " '¬dysp10': -9,\n",
              " 'dysp11': 10,\n",
              " '¬dysp11': -10,\n",
              " 'lung': 11,\n",
              " '¬lung': -11,\n",
              " 'tub': 12,\n",
              " '¬tub': -12,\n",
              " 'either00': 13,\n",
              " '¬either00': -13,\n",
              " 'either01': 14,\n",
              " '¬either01': -14,\n",
              " 'either10': 15,\n",
              " '¬either10': -15,\n",
              " 'either11': 16,\n",
              " '¬either11': -16,\n",
              " 'lung0': 17,\n",
              " '¬lung0': -17,\n",
              " 'lung1': 18,\n",
              " '¬lung1': -18,\n",
              " 'asia': 19,\n",
              " '¬asia': -19,\n",
              " 'tub0': 20,\n",
              " '¬tub0': -20,\n",
              " 'tub1': 21,\n",
              " '¬tub1': -21,\n",
              " 'xray': 22,\n",
              " '¬xray': -22,\n",
              " 'xray0': 23,\n",
              " '¬xray0': -23,\n",
              " 'xray1': 24,\n",
              " '¬xray1': -24}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Use the same symbol mapping to update the literals in the generated equivalences"
      ],
      "metadata": {
        "id": "6Brz6RK1EfXV"
      },
      "id": "6Brz6RK1EfXV"
    },
    {
      "cell_type": "code",
      "source": [
        "def update_equivalences(equivalences, symbol_mapping):\n",
        "    updated_equivalences = []\n",
        "\n",
        "    for implication in equivalences:\n",
        "        updated_implication = implication\n",
        "\n",
        "        sorted_items = sorted(symbol_mapping.items(), key=lambda x: len(x[0]), reverse=True)\n",
        "\n",
        "        for literal, number in sorted_items:\n",
        "            updated_implication = updated_implication.replace(literal, str(number))\n",
        "\n",
        "        updated_equivalences.append(updated_implication)\n",
        "\n",
        "    return updated_equivalences"
      ],
      "metadata": {
        "id": "2AlJEJxnk5xA"
      },
      "id": "2AlJEJxnk5xA",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_equivalences = update_equivalences(equivalences, symbol_mapping)"
      ],
      "metadata": {
        "id": "mwnsjUTDk8jQ"
      },
      "id": "mwnsjUTDk8jQ",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_equivalences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG6bNlXKlBWj",
        "outputId": "adeda85a-a541-4fa1-a3eb-9730571c9dae"
      },
      "id": "GG6bNlXKlBWj",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1 ∧ -2 → 3',\n",
              " '-1 ∧ -2 → -3',\n",
              " '1 ∧ 2 → 4',\n",
              " '-1 ∧ 2 → -4',\n",
              " '5 ∧ -1 ∧ -6 → 7',\n",
              " '-5 ∧ -1 ∧ -6 → -7',\n",
              " '5 ∧ 6 ∧ -1 → 8',\n",
              " '-5 ∧ 6 ∧ -1 → -8',\n",
              " '5 ∧ 1 ∧ -6 → 9',\n",
              " '-5 ∧ 1 ∧ -6 → -9',\n",
              " '5 ∧ 1 ∧ 6 → 10',\n",
              " '-5 ∧ 1 ∧ 6 → -10',\n",
              " '6 ∧ -11 ∧ -12 → 13',\n",
              " '-6 ∧ -11 ∧ -12 → -13',\n",
              " '6 ∧ 12 ∧ -11 → 14',\n",
              " '-6 ∧ 12 ∧ -11 → -14',\n",
              " '6 ∧ 11 ∧ -12 → 15',\n",
              " '-6 ∧ 11 ∧ -12 → -15',\n",
              " '6 ∧ 11 ∧ 12 → 16',\n",
              " '-6 ∧ 11 ∧ 12 → -16',\n",
              " '11 ∧ -2 → 17',\n",
              " '-11 ∧ -2 → -17',\n",
              " '11 ∧ 2 → 18',\n",
              " '-11 ∧ 2 → -18',\n",
              " '12 ∧ -19 → 20',\n",
              " '-12 ∧ -19 → -20',\n",
              " '12 ∧ 19 → 21',\n",
              " '-12 ∧ 19 → -21',\n",
              " '22 ∧ -6 → 23',\n",
              " '-22 ∧ -6 → -23',\n",
              " '22 ∧ 6 → 24',\n",
              " '-22 ∧ 6 → -24']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. In order to have the formula in the required format by the SAT solver, I have build two auxilary functions to be used by the final function that prepares the final formula for such a solver.\n",
        "\n",
        "\n",
        "\n",
        "> Step 1: Transform the implication into CNF\n",
        "\n",
        "After applying this function to an implication this is how it will look like below, which is not in the format required by MiniSat solver. I will use another function to parse the formula to the required format:\n",
        "\n",
        "   \n",
        "\n",
        "*   implication = \"22 ∧ 6 → 24\"\n",
        "*   cnf = implication_to_cnf(implication)\n",
        "*   print(cnf)\n",
        "*   (¬22 ∨ ¬6 ∨ 24)\n",
        "\n",
        "\n",
        "\n",
        "> Step 2: Format the resulted CNF\n",
        "\n",
        "*   [¬22 , ¬6, 24]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "   \n",
        "   \n"
      ],
      "metadata": {
        "id": "WgBBsDWeIKIi"
      },
      "id": "WgBBsDWeIKIi"
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy import symbols, Or, Not, And\n",
        "from sympy.logic.boolalg import to_cnf\n",
        "def implication_to_cnf(implication):\n",
        "    \"\"\"\n",
        "    Converts a logical implication into its Conjunctive Normal Form (CNF).\n",
        "\n",
        "    Parameters:\n",
        "    - implication (str): A string representing a logical implication in the form \"LHS → RHS\",\n",
        "      where LHS is a conjunction of literals separated by '∧' and RHS is a single literal.\n",
        "      Negated literals are prefixed with '¬'.\n",
        "\n",
        "    Returns:\n",
        "    - sympy.logic.boolalg.Boolean: A SymPy expression representing the CNF of the given implication.\n",
        "\n",
        "    The function performs the following steps:\n",
        "    1. Splits the implication into its Left-Hand Side (LHS) and Right-Hand Side (RHS).\n",
        "    2. Converts the literals in the LHS and RHS to SymPy symbols, handling negations appropriately.\n",
        "    3. Creates a SymPy expression for the implication.\n",
        "    4. Converts the implication expression to its CNF using SymPy's `to_cnf` function.\n",
        "    \"\"\"\n",
        "    # Split implication into LHS and RHS\n",
        "    lhs, rhs = implication.split('→')\n",
        "    lhs = lhs.strip()\n",
        "    rhs = rhs.strip()\n",
        "\n",
        "    # Convert to sympy symbols\n",
        "    lhs_symbols = [symbols(lit.strip()) if not lit.strip().startswith('¬') else Not(symbols(lit.strip()[1:])) for lit in lhs.split('∧')]\n",
        "    rhs_symbol = symbols(rhs) if not rhs.startswith('¬') else Not(symbols(rhs[1:].strip()))\n",
        "\n",
        "    # Create implication and convert to CNF\n",
        "    implication_expr = Or(Not(And(*lhs_symbols)), rhs_symbol)\n",
        "    cnf_expr = to_cnf(implication_expr, simplify=True)\n",
        "\n",
        "    return cnf_expr"
      ],
      "metadata": {
        "id": "il4RnunKdiTE"
      },
      "id": "il4RnunKdiTE",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy import Or, Not, Symbol\n",
        "\n",
        "def format_cnf_clause(clause):\n",
        "\n",
        "    \"\"\"\n",
        "    Formats a CNF clause into a list of integers.\n",
        "\n",
        "    Parameters:\n",
        "    - clause (sympy.logic.boolalg.Boolean): A SymPy Boolean expression representing a CNF clause.\n",
        "      The clause can be an instance of `Or`, `Not`, or `Symbol`.\n",
        "\n",
        "    Returns:\n",
        "    - list: A list of integers where each integer corresponds to a literal in the clause.\n",
        "      Positive integers represent positive literals, and negative integers represent negated literals.\n",
        "\n",
        "    The function performs the following steps:\n",
        "    1. Ensures the clause is an `Or` expression. If it is not, it converts it to an `Or` expression.\n",
        "    2. Iterates over the arguments of the `Or` expression.\n",
        "    3. For each argument, if it is a negation (`Not`), it extracts the literal and negates its integer value.\n",
        "       If it is a positive literal (`Symbol`), it converts it directly to an integer.\n",
        "    4. Collects the formatted literals in a list and returns it.\n",
        "    \"\"\"\n",
        "    if not isinstance(clause, Or):\n",
        "        clause = Or(clause)\n",
        "\n",
        "    formatted_clause = []\n",
        "\n",
        "    for arg in clause.args:\n",
        "        if isinstance(arg, Not):\n",
        "            literal = -int(str(arg.args[0]))\n",
        "        elif isinstance(arg, Symbol):\n",
        "            literal = int(str(arg))\n",
        "        else:\n",
        "            literal = int(str(arg))\n",
        "        formatted_clause.append(literal)\n",
        "\n",
        "    return formatted_clause"
      ],
      "metadata": {
        "id": "QsKDwWNKrlKo"
      },
      "id": "QsKDwWNKrlKo",
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def format_cnf_clause2(clause_str):\n",
        "\n",
        "    literals = clause_str.split('|')\n",
        "    formatted_clause = []\n",
        "\n",
        "    for literal in literals:\n",
        "        literal = literal.strip()\n",
        "        if literal.startswith('~-'):\n",
        "            formatted_clause.append(int(literal[2:]))  # Remove '~-' and convert to positive integer\n",
        "        elif literal.startswith('~'):\n",
        "            formatted_clause.append(-int(literal[1:]))  # Remove '~' and negate\n",
        "        else:\n",
        "            formatted_clause.append(int(literal))\n",
        "\n",
        "    return formatted_clause\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "A0VzKYBgrM43"
      },
      "id": "A0VzKYBgrM43",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Finally, we can use the functions implemented to generate the CNF clauses to be inserted in SAT solver"
      ],
      "metadata": {
        "id": "XauGn-SWGMKX"
      },
      "id": "XauGn-SWGMKX"
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_cnf2(updated_equivalences):\n",
        "\n",
        "  cnf = CNF()\n",
        "  for implication in updated_equivalences:\n",
        "\n",
        "    cnf_expr = implication_to_cnf(implication)\n",
        "    formated_one = format_cnf_clause(cnf_expr)\n",
        "    cnf.append(formated_one)\n",
        "\n",
        "  return cnf\n"
      ],
      "metadata": {
        "id": "DQsZfsMkox2q"
      },
      "id": "DQsZfsMkox2q",
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf  = transform_to_cnf2(updated_equivalences)"
      ],
      "metadata": {
        "id": "GrXWt6nbt_Hn"
      },
      "id": "GrXWt6nbt_Hn",
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2nTBNFXuGfh",
        "outputId": "14213b9f-08e5-4c2d-e6b3-929b1e853064"
      },
      "id": "F2nTBNFXuGfh",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNF(from_string='p cnf 24 32\\n3 2 -1 0\\n-3 1 2 0\\n4 -1 -2 0\\n-4 1 -2 0\\n7 1 6 -5 0\\n-7 1 5 6 0\\n8 1 -5 -6 0\\n-8 1 5 -6 0\\n9 6 -1 -5 0\\n-9 5 6 -1 0\\n10 -1 -5 -6 0\\n-10 5 -1 -6 0\\n13 11 12 -6 0\\n-13 11 12 6 0\\n14 11 -12 -6 0\\n-14 11 6 -12 0\\n15 12 -11 -6 0\\n-15 12 6 -11 0\\n16 -11 -12 -6 0\\n-16 6 -11 -12 0\\n17 2 -11 0\\n-17 11 2 0\\n18 -11 -2 0\\n-18 11 -2 0\\n20 19 -12 0\\n-20 12 19 0\\n21 -12 -19 0\\n-21 12 -19 0\\n23 6 -22 0\\n-23 22 6 0\\n24 -22 -6 0\\n-24 22 -6 0')"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities to prepare weights for our model"
      ],
      "metadata": {
        "id": "sE12_2oJMc7k"
      },
      "id": "sE12_2oJMc7k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Recall that the dictionary that contains the weights for all the literals already exist. Now, I need to mapp each of the literals to its integer value based on the symbol_mapping dictionary"
      ],
      "metadata": {
        "id": "y-WtGL9TMv0f"
      },
      "id": "y-WtGL9TMv0f"
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_symbol_mapping_to_weights(weight_dict, symbol_mapping):\n",
        "\n",
        "    \"\"\"\n",
        "    Applies a symbol mapping to a dictionary of weights, converting symbol keys to their corresponding mapped integer values.\n",
        "\n",
        "    Parameters:\n",
        "    - weight_dict (dict): A dictionary where keys are symbol strings and values are their corresponding weights (floats).\n",
        "    - symbol_mapping (dict): A dictionary that maps symbol strings to integer values. Positive and negative literals\n",
        "                             should have the same integer value but opposite signs.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A new dictionary where the keys are the mapped integer values from `symbol_mapping` and the values are the\n",
        "            corresponding weights from `weight_dict`.\n",
        "    \"\"\"\n",
        "\n",
        "    mapped_weight_dict = {}\n",
        "\n",
        "\n",
        "    for key, value in weight_dict.items():\n",
        "      if f'{key}' in symbol_mapping:\n",
        "        mapped_key = symbol_mapping[f'{key}']\n",
        "        mapped_weight_dict[mapped_key] = value\n",
        "\n",
        "    return mapped_weight_dict"
      ],
      "metadata": {
        "id": "6EAzOOBdYfUF"
      },
      "id": "6EAzOOBdYfUF",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapped_weight_dict = apply_symbol_mapping_to_weights(all_weights, symbol_mapping)"
      ],
      "metadata": {
        "id": "NMXeyyoYRK2N"
      },
      "id": "NMXeyyoYRK2N",
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Based on our PHI, the SAT solver returns the models that satisfy it. Essentially, we need to get the weights from our dictionary of the literals that compose this model"
      ],
      "metadata": {
        "id": "vPJg9xgwNLvo"
      },
      "id": "vPJg9xgwNLvo"
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_weights_of_literals_for_given_model(mapped_weight_dict, model):\n",
        "\n",
        "  \"\"\"\n",
        "    Extracts the weights of literals for a given model based on a mapped weight dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    - mapped_weight_dict (dict): A dictionary where keys are integer representations of literals and values are their corresponding weights (floats).\n",
        "    - model (list of int): A list of integers representing the literals in the given model.\n",
        "\n",
        "    Returns:\n",
        "    - list of float: A list of weights corresponding to the literals in the given model.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  literal_weight_values = []\n",
        "\n",
        "\n",
        "  for key in model:\n",
        "\n",
        "    literal_weight_values.append(mapped_weight_dict[key])\n",
        "\n",
        "  return literal_weight_values\n"
      ],
      "metadata": {
        "id": "LwJR8iw46LOO"
      },
      "id": "LwJR8iw46LOO",
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. As the literals that compose this model are in a conjuction, we need to multiply their weights. When calculatin the weight of our PHI, as we will see, we need to sum all of them"
      ],
      "metadata": {
        "id": "HncbH7HaN5P_"
      },
      "id": "HncbH7HaN5P_"
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_of_given_model(literal_weight_values):\n",
        "\n",
        "  product = 1\n",
        "  for literal_weight in literal_weight_values:\n",
        "    product *= literal_weight\n",
        "\n",
        "  return product"
      ],
      "metadata": {
        "id": "KgZEGL-Z7KdT"
      },
      "id": "KgZEGL-Z7KdT",
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Lastly, to make it easy to find the correspondent int mapping for a given literal when calculating the probablity, I use the function below"
      ],
      "metadata": {
        "id": "y1nBSipQORWP"
      },
      "id": "y1nBSipQORWP"
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_int_mapping(literal,symbol_mapping):\n",
        "\n",
        "  representative_value = []\n",
        "\n",
        "  for l in literal:\n",
        "    r  = symbol_mapping[f'{l}']\n",
        "    representative_value.append(r)\n",
        "\n",
        "  return representative_value"
      ],
      "metadata": {
        "id": "J6fQ_sKf_rap"
      },
      "id": "J6fQ_sKf_rap",
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the functionalities created"
      ],
      "metadata": {
        "id": "NQmR6u-_OsIc"
      },
      "id": "NQmR6u-_OsIc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Check if the WMC of PHI is 1"
      ],
      "metadata": {
        "id": "EqJKxYgRPc32"
      },
      "id": "EqJKxYgRPc32"
    },
    {
      "cell_type": "code",
      "source": [
        "WMC_phi = 0\n",
        "phi_b = Minisat22(bootstrap_with = cnf.clauses)\n",
        "for models in phi_b.enum_models():\n",
        "  WMC_phi += weight_of_given_model(extract_weights_of_literals_for_given_model(mapped_weight_dict, models))\n",
        "\n",
        "print(round(WMC_phi,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbKVmfDf7zvy",
        "outputId": "a8bb1e69-af19-451b-daf5-b83554777e71"
      },
      "id": "JbKVmfDf7zvy",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Before each test, clean CNF clauses and initialize it with the initial clauses"
      ],
      "metadata": {
        "id": "XFMP2SMePlNM"
      },
      "id": "XFMP2SMePlNM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> First experiment\n",
        "\n"
      ],
      "metadata": {
        "id": "3fxG1aEwR7Xe"
      },
      "id": "3fxG1aEwR7Xe"
    },
    {
      "cell_type": "code",
      "source": [
        "# negation symbol   ¬\n",
        "literal = ['asia','bronc','¬dysp','either','lung','smoke']\n",
        "\n",
        "representative_value = extract_int_mapping(literal,symbol_mapping)\n",
        "\n",
        "representative_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D_YRymERJYc",
        "outputId": "503739c6-3acd-4fa5-eebc-2f8978372b1f"
      },
      "id": "2D_YRymERJYc",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[19, 1, -5, 6, 11, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf = transform_to_cnf2(updated_equivalences)"
      ],
      "metadata": {
        "id": "57rfJT2i7lx2"
      },
      "id": "57rfJT2i7lx2",
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is how I add the evidence\n",
        "cnf.append([19])\n",
        "cnf.append([1])\n",
        "cnf.append([-5])\n",
        "cnf.append([6])\n",
        "cnf.append([11])\n",
        "s1 = Minisat22(bootstrap_with=cnf.clauses)\n",
        "\n",
        "WMC_den = 0\n",
        "for models in s1.enum_models():\n",
        "    WMC_den += weight_of_given_model(extract_weights_of_literals_for_given_model(mapped_weight_dict, models))"
      ],
      "metadata": {
        "id": "R3gF2LUp9FZr"
      },
      "id": "R3gF2LUp9FZr",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is how I add the query\n",
        "cnf.append([-2])\n",
        "s2 = Minisat22(bootstrap_with=cnf.clauses)\n",
        "\n",
        "WMC_num = 0\n",
        "for models in s2.enum_models():\n",
        "    WMC_num += weight_of_given_model(extract_weights_of_literals_for_given_model(mapped_weight_dict, models))"
      ],
      "metadata": {
        "id": "KTjasgji-esX"
      },
      "id": "KTjasgji-esX",
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(round(WMC_num / WMC_den, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkRhGVvt-rh-",
        "outputId": "5bb5076c-38a6-4168-d251-08d4d1128c48"
      },
      "id": "jkRhGVvt-rh-",
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = bn.import_DAG('asia')\n",
        "query = bn.inference.fit(model, variables=['smoke'], evidence={\"asia\":1, \"bronc\":1, \"dysp\":0, \"either\":1, 'lung':1}, joint = True)\n",
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpjx1OyvSq2w",
        "outputId": "5862841b-f7f9-463e-f02a-1d700c1f5df7"
      },
      "id": "Cpjx1OyvSq2w",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[bnlearn] >Import <asia>\n",
            "[bnlearn] >Loading bif file </usr/local/lib/python3.10/dist-packages/datazets/data/asia.bif>\n",
            "[bnlearn] >Check whether CPDs sum up to one.\n",
            "[bnlearn] >Variable Elimination.\n",
            "[bnlearn] >Warning: variable(s) [None] does not exists in DAG.\n",
            "[bnlearn] >Data is stored in [query.df]\n",
            "+----+---------+---------+\n",
            "|    |   smoke |       p |\n",
            "+====+=========+=========+\n",
            "|  0 |       0 | 0.34188 |\n",
            "+----+---------+---------+\n",
            "|  1 |       1 | 0.65812 |\n",
            "+----+---------+---------+\n",
            "+----------+--------------+\n",
            "| smoke    |   phi(smoke) |\n",
            "+==========+==============+\n",
            "| smoke(0) |       0.3419 |\n",
            "+----------+--------------+\n",
            "| smoke(1) |       0.6581 |\n",
            "+----------+--------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Second experiment\n",
        "\n"
      ],
      "metadata": {
        "id": "JW5meCO5UPx_"
      },
      "id": "JW5meCO5UPx_"
    },
    {
      "cell_type": "code",
      "source": [
        "# negation symbol   ¬\n",
        "literal = ['lung','bronc','¬dysp','xray','tub']\n",
        "\n",
        "representative_value = extract_int_mapping(literal,symbol_mapping)\n",
        "\n",
        "representative_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1DeFzn-VGzW",
        "outputId": "e1517df7-d951-480b-9477-8fe9206943b3"
      },
      "id": "k1DeFzn-VGzW",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11, 1, -5, 22, 12]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf = transform_to_cnf2(updated_equivalences)"
      ],
      "metadata": {
        "id": "i6yMaM_bVSPR"
      },
      "id": "i6yMaM_bVSPR",
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is how I add the evidence\n",
        "cnf.append([11])\n",
        "cnf.append([1])\n",
        "cnf.append([-5])\n",
        "cnf.append([22])\n",
        "s1 = Minisat22(bootstrap_with=cnf.clauses)\n",
        "\n",
        "WMC_den = 0\n",
        "for models in s1.enum_models():\n",
        "    WMC_den += weight_of_given_model(extract_weights_of_literals_for_given_model(mapped_weight_dict, models))"
      ],
      "metadata": {
        "id": "FBoKTrycVW2j"
      },
      "id": "FBoKTrycVW2j",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is how I add the query\n",
        "cnf.append([-12])\n",
        "s2 = Minisat22(bootstrap_with=cnf.clauses)\n",
        "\n",
        "WMC_num = 0\n",
        "for models in s2.enum_models():\n",
        "    WMC_num += weight_of_given_model(extract_weights_of_literals_for_given_model(mapped_weight_dict, models))"
      ],
      "metadata": {
        "id": "poa28ZBqVgdZ"
      },
      "id": "poa28ZBqVgdZ",
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Numerator contains clauses of PHI, question, and evidence\n",
        "\n",
        "\n",
        "> Denominator contains clauses of PHI and evidence\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QcVyKwBmW5s1"
      },
      "id": "QcVyKwBmW5s1"
    },
    {
      "cell_type": "code",
      "source": [
        "print(round(WMC_num / WMC_den, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZnKqT6_Vkx4",
        "outputId": "cdf629e8-2b88-4456-fdc3-72af3c45ecbc"
      },
      "id": "IZnKqT6_Vkx4",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = bn.import_DAG('asia')\n",
        "query = bn.inference.fit(model, variables=['tub'], evidence={'lung':1,'bronc':1,'dysp':0,'xray':1 }, joint = True)\n",
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4hV-mWXVnoA",
        "outputId": "4ebc0ae2-1fde-4277-da9c-2743583a94e4"
      },
      "id": "_4hV-mWXVnoA",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[bnlearn] >Import <asia>\n",
            "[bnlearn] >Loading bif file </usr/local/lib/python3.10/dist-packages/datazets/data/asia.bif>\n",
            "[bnlearn] >Check whether CPDs sum up to one.\n",
            "[bnlearn] >Variable Elimination.\n",
            "[bnlearn] >Warning: variable(s) [None] does not exists in DAG.\n",
            "[bnlearn] >Data is stored in [query.df]\n",
            "+----+-------+------------+\n",
            "|    |   tub |          p |\n",
            "+====+=======+============+\n",
            "|  0 |     0 | 0.00154634 |\n",
            "+----+-------+------------+\n",
            "|  1 |     1 | 0.998454   |\n",
            "+----+-------+------------+\n",
            "+--------+------------+\n",
            "| tub    |   phi(tub) |\n",
            "+========+============+\n",
            "| tub(0) |     0.0015 |\n",
            "+--------+------------+\n",
            "| tub(1) |     0.9985 |\n",
            "+--------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second dataset"
      ],
      "metadata": {
        "id": "IVMI6ZSzZTus"
      },
      "id": "IVMI6ZSzZTus"
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = [\"sprinkler\"]\n",
        "\n",
        "dataset = datasets[0]\n",
        "\n",
        "df = bn.import_DAG(dataset, CPD = True)\n",
        "CPDs_sprink = bn.print_CPD(df, verbose = 1)\n",
        "print(CPDs_sprink.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMBRBoKIZWyi",
        "outputId": "6c45d8d8-fbb3-4ecf-fc04-b2252675dfa6"
      },
      "id": "yMBRBoKIZWyi",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[bnlearn] >Import <sprinkler>\n",
            "[bnlearn] >Check whether CPDs sum up to one.\n",
            "dict_keys(['Cloudy', 'Sprinkler', 'Rain', 'Wet_Grass'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Print CPTs to see the structure\n",
        "2.   Get parent dictionary\n",
        "3.   Create propositional variables\n",
        "4.   Assign weights to literals\n",
        "5.   Generate implications\n",
        "6.   Create literal mapping to int values\n",
        "7.   Update implications with int values of literals\n",
        "8.   Transform implications into CNF\n",
        "9.   Update wight dictionary with int values of literals\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rWZq0ftHbdGq"
      },
      "id": "rWZq0ftHbdGq"
    },
    {
      "cell_type": "code",
      "source": [
        "CPDs_sprink"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_Ptpn5TcFcl",
        "outputId": "43299da3-b86f-4970-d796-ac6db0370969"
      },
      "id": "w_Ptpn5TcFcl",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cloudy':    Cloudy    p\n",
              " 0       0  0.5\n",
              " 1       1  0.5,\n",
              " 'Sprinkler':    Sprinkler  Cloudy    p\n",
              " 0          0       0  0.5\n",
              " 1          0       1  0.9\n",
              " 2          1       0  0.5\n",
              " 3          1       1  0.1,\n",
              " 'Rain':    Rain  Cloudy    p\n",
              " 0     0       0  0.8\n",
              " 1     0       1  0.2\n",
              " 2     1       0  0.2\n",
              " 3     1       1  0.8,\n",
              " 'Wet_Grass':    Wet_Grass  Sprinkler  Rain     p\n",
              " 0          0          0     0  1.00\n",
              " 1          0          0     1  0.10\n",
              " 2          0          1     0  0.10\n",
              " 3          0          1     1  0.01\n",
              " 4          1          0     0  0.00\n",
              " 5          1          0     1  0.90\n",
              " 6          1          1     0  0.90\n",
              " 7          1          1     1  0.99}"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parent_dict_sprink = get_parents_dict(CPDs_sprink)\n",
        "all_vars_sprink, var_symbols_sprink, indicator_vars_sprink = create_propositional_variables(CPDs_sprink, parent_dict_sprink)\n",
        "indicator_vars_sprink"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yLSdFxkcIr2",
        "outputId": "d0a5f978-3f1a-4dee-86be-7598038b62f4"
      },
      "id": "3yLSdFxkcIr2",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cloudy': Cloudy,\n",
              " 'Sprinkler': Sprinkler,\n",
              " 'Sprinkler0': Sprinkler0,\n",
              " 'Sprinkler1': Sprinkler1,\n",
              " 'Rain': Rain,\n",
              " 'Rain0': Rain0,\n",
              " 'Rain1': Rain1,\n",
              " 'Wet_Grass': Wet_Grass,\n",
              " 'Wet_Grass00': Wet_Grass00,\n",
              " 'Wet_Grass01': Wet_Grass01,\n",
              " 'Wet_Grass10': Wet_Grass10,\n",
              " 'Wet_Grass11': Wet_Grass11}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights_sprink = assign_weights(CPDs_sprink, parent_dict_sprink, indicator_vars_sprink)\n",
        "all_weights_sprink"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DVzetEScZTa",
        "outputId": "dd406a2a-6a73-425b-cf5e-48b7c901cb8e"
      },
      "id": "-DVzetEScZTa",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Cloudy: 0.5,\n",
              " Sprinkler0: 0.5,\n",
              " Sprinkler1: 0.1,\n",
              " Rain0: 0.2,\n",
              " Rain1: 0.8,\n",
              " Wet_Grass00: 0.0,\n",
              " Wet_Grass01: 0.9,\n",
              " Wet_Grass10: 0.9,\n",
              " Wet_Grass11: 0.99,\n",
              " ¬Cloudy: 0.5,\n",
              " ¬Sprinkler0: 0.5,\n",
              " ¬Sprinkler1: 0.9,\n",
              " ¬Rain0: 0.8,\n",
              " ¬Rain1: 0.2,\n",
              " ¬Wet_Grass00: 1.0,\n",
              " ¬Wet_Grass01: 0.1,\n",
              " ¬Wet_Grass10: 0.1,\n",
              " ¬Wet_Grass11: 0.01,\n",
              " Rain: 1.0,\n",
              " ¬Rain: 1.0,\n",
              " Sprinkler: 1.0,\n",
              " ¬Sprinkler: 1.0,\n",
              " Wet_Grass: 1.0,\n",
              " ¬Wet_Grass: 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "equivalences_sprink = generate_equivalences(CPDs_sprink)\n",
        "equivalences_sprink"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU_DmTZecgGF",
        "outputId": "74791bb9-ebe3-44e9-b8f4-0852c10e06d2"
      },
      "id": "bU_DmTZecgGF",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sprinkler ∧ ¬Cloudy → Sprinkler0',\n",
              " '¬Sprinkler ∧ ¬Cloudy → ¬Sprinkler0',\n",
              " 'Sprinkler ∧ Cloudy → Sprinkler1',\n",
              " '¬Sprinkler ∧ Cloudy → ¬Sprinkler1',\n",
              " 'Rain ∧ ¬Cloudy → Rain0',\n",
              " '¬Rain ∧ ¬Cloudy → ¬Rain0',\n",
              " 'Rain ∧ Cloudy → Rain1',\n",
              " '¬Rain ∧ Cloudy → ¬Rain1',\n",
              " 'Wet_Grass ∧ ¬Sprinkler ∧ ¬Rain → Wet_Grass00',\n",
              " '¬Wet_Grass ∧ ¬Sprinkler ∧ ¬Rain → ¬Wet_Grass00',\n",
              " 'Wet_Grass ∧ Rain ∧ ¬Sprinkler → Wet_Grass01',\n",
              " '¬Wet_Grass ∧ Rain ∧ ¬Sprinkler → ¬Wet_Grass01',\n",
              " 'Wet_Grass ∧ Sprinkler ∧ ¬Rain → Wet_Grass10',\n",
              " '¬Wet_Grass ∧ Sprinkler ∧ ¬Rain → ¬Wet_Grass10',\n",
              " 'Wet_Grass ∧ Sprinkler ∧ Rain → Wet_Grass11',\n",
              " '¬Wet_Grass ∧ Sprinkler ∧ Rain → ¬Wet_Grass11']"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symbol_mapping_sprink = create_symbol_mapping(equivalences_sprink)"
      ],
      "metadata": {
        "id": "mwGOfs1RcmH7"
      },
      "id": "mwGOfs1RcmH7",
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_equivalences_sprink = update_equivalences(equivalences_sprink , symbol_mapping_sprink)\n",
        "updated_equivalences_sprink"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbB-olwZcr_A",
        "outputId": "6371ba44-ab0c-4842-a61d-66bf4d40781e"
      },
      "id": "IbB-olwZcr_A",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1 ∧ -2 → 3',\n",
              " '-1 ∧ -2 → -3',\n",
              " '1 ∧ 2 → 4',\n",
              " '-1 ∧ 2 → -4',\n",
              " '5 ∧ -2 → 6',\n",
              " '-5 ∧ -2 → -6',\n",
              " '5 ∧ 2 → 7',\n",
              " '-5 ∧ 2 → -7',\n",
              " '8 ∧ -1 ∧ -5 → 9',\n",
              " '-8 ∧ -1 ∧ -5 → -9',\n",
              " '8 ∧ 5 ∧ -1 → 10',\n",
              " '-8 ∧ 5 ∧ -1 → -10',\n",
              " '8 ∧ 1 ∧ -5 → 11',\n",
              " '-8 ∧ 1 ∧ -5 → -11',\n",
              " '8 ∧ 1 ∧ 5 → 12',\n",
              " '-8 ∧ 1 ∧ 5 → -12']"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_sprink = transform_to_cnf2(updated_equivalences_sprink)\n",
        "cnf_sprink"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnlrV74HczOi",
        "outputId": "a566e7c2-b561-4bbf-a66f-03fdd53ded8f"
      },
      "id": "jnlrV74HczOi",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNF(from_string='p cnf 12 16\\n3 2 -1 0\\n-3 1 2 0\\n4 -1 -2 0\\n-4 1 -2 0\\n6 2 -5 0\\n-6 2 5 0\\n7 -2 -5 0\\n-7 5 -2 0\\n9 1 5 -8 0\\n-9 1 5 8 0\\n10 1 -5 -8 0\\n-10 1 8 -5 0\\n11 5 -1 -8 0\\n-11 5 8 -1 0\\n12 -1 -5 -8 0\\n-12 8 -1 -5 0')"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapped_weight_dict_sprink = apply_symbol_mapping_to_weights(all_weights_sprink, symbol_mapping_sprink)"
      ],
      "metadata": {
        "id": "wWxZGFuqc59t"
      },
      "id": "wWxZGFuqc59t",
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test functionalities in the second dataset"
      ],
      "metadata": {
        "id": "Ppel2UPVdiDQ"
      },
      "id": "Ppel2UPVdiDQ"
    },
    {
      "cell_type": "code",
      "source": [
        "WMC_phi_sprink = 0\n",
        "phi_b_sprink = Minisat22(bootstrap_with = cnf_sprink.clauses)\n",
        "for models in phi_b_sprink.enum_models():\n",
        "  WMC_phi_sprink += weight_of_given_model(extract_weights_of_literals_for_given_model(mapped_weight_dict_sprink, models))\n",
        "\n",
        "print(round(WMC_phi_sprink,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-6QYCvndmgr",
        "outputId": "9553f794-30e9-4c9f-e034-f479897e4f70"
      },
      "id": "h-6QYCvndmgr",
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# negation symbol   ¬\n",
        "literal_sprink = ['Cloudy','Rain','¬Wet_Grass']\n",
        "\n",
        "representative_value_sprink = extract_int_mapping(literal_sprink,symbol_mapping_sprink)\n",
        "\n",
        "representative_value_sprink"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLE8XBSldzcA",
        "outputId": "af1365c5-e5e4-4756-9596-02628d293e3f"
      },
      "id": "zLE8XBSldzcA",
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 5, -8]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_sprink = transform_to_cnf2(updated_equivalences_sprink)"
      ],
      "metadata": {
        "id": "X19GbviWeCYP"
      },
      "id": "X19GbviWeCYP",
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is how I add the evidence\n",
        "cnf_sprink.append([2])\n",
        "cnf_sprink.append([5])\n",
        "s1_sprink = Minisat22(bootstrap_with=cnf_sprink.clauses)\n",
        "WMC_den_sprink = 0\n",
        "for models in s1_sprink.enum_models():\n",
        "    WMC_den_sprink += weight_of_given_model(extract_weights_of_literals_for_given_model(mapped_weight_dict_sprink, models))"
      ],
      "metadata": {
        "id": "DpbYAxO2eIyC"
      },
      "id": "DpbYAxO2eIyC",
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is how I add the query\n",
        "cnf_sprink.append([-8])\n",
        "s2_sprink = Minisat22(bootstrap_with=cnf_sprink.clauses)\n",
        "\n",
        "WMC_num_sprink = 0\n",
        "for models in s2_sprink.enum_models():\n",
        "    WMC_num_sprink += weight_of_given_model(extract_weights_of_literals_for_given_model(mapped_weight_dict_sprink, models))"
      ],
      "metadata": {
        "id": "tB5bg_J1ej-O"
      },
      "id": "tB5bg_J1ej-O",
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(round(WMC_num_sprink / WMC_den_sprink, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnjaCPeiewM2",
        "outputId": "ac31f6db-7e70-4714-9fcd-f10d99b0c9f6"
      },
      "id": "mnjaCPeiewM2",
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = bn.import_DAG('sprinkler')\n",
        "query = bn.inference.fit(model, variables=['Wet_Grass'], evidence={\"Cloudy\":1, 'Rain':1}, joint = True)\n",
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wv7W0uOez1P",
        "outputId": "84feb4f7-4bc5-47db-bb19-2d614fe12c05"
      },
      "id": "9Wv7W0uOez1P",
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[bnlearn] >Import <sprinkler>\n",
            "[bnlearn] >Check whether CPDs sum up to one.\n",
            "[bnlearn] >Variable Elimination.\n",
            "[bnlearn] >Warning: variable(s) [None] does not exists in DAG.\n",
            "[bnlearn] >Data is stored in [query.df]\n",
            "+----+-------------+-------+\n",
            "|    |   Wet_Grass |     p |\n",
            "+====+=============+=======+\n",
            "|  0 |           0 | 0.091 |\n",
            "+----+-------------+-------+\n",
            "|  1 |           1 | 0.909 |\n",
            "+----+-------------+-------+\n",
            "+--------------+------------------+\n",
            "| Wet_Grass    |   phi(Wet_Grass) |\n",
            "+==============+==================+\n",
            "| Wet_Grass(0) |           0.0910 |\n",
            "+--------------+------------------+\n",
            "| Wet_Grass(1) |           0.9090 |\n",
            "+--------------+------------------+\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}